akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = INFO
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  remote.artery {
    canonical {
      hostname = "127.0.0.1"
      port = 2551
    }
  }
  cluster {
    seed-nodes = ["akka://AccountActor@127.0.0.1:2551"]
  }

  actor {
    debug {
      unhandled = off
      lifecycle = off
    }
    provider = "cluster"


    serialization-identifiers {
      jackson-json-event = 9009
    }

    serialization-bindings {
      "com.example.banking.JsonSerializer" = jackson-json
    }


    default-dispatcher{
      fork-join-executor {
        parallelism-min = 4
        parallelism-factor = 2.0
        parallelism-max = 8
      }
    }
  }
  # use Cassandra to store both snapshots and the events of the persistent actors
  persistence {
    journal.plugin = "akka.persistence.cassandra.journal"
    snapshot-store.plugin = "akka.persistence.cassandra.snapshot"
  }
  management {
    http {
      hostname = "127.0.0.1"
      port = 8552
    }
  }
}

# Configuration for akka-persistence-cassandra
akka.persistence.cassandra {

  events-by-tag {
    bucket-size = "Day"
    # for reduced latency
    eventual-consistency-delay = 200ms
    flush-interval = 50ms
    pubsub-notification = on
    first-time-bucket = "20200115T00:00"
  }

  query {
    refresh-interval = 2s
  }

  journal.class = "akka.persistence.cassandra.journal.CassandraJournal"


  # don't use autocreate in production
  journal.keyspace-autocreate = on
  journal.tables-autocreate = on
  snapshot.keyspace-autocreate = on
  snapshot.tables-autocreate = on
}

datastax-java-driver {
  advanced.reconnect-on-init = on
}
